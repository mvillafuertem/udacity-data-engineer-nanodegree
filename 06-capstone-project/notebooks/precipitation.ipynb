{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37764bitdendcondacf54d56bf2ff408b9345a9eba404596b",
   "display_name": "Python 3.7.7 64-bit ('dend': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data analysis of Precipitation data\n",
    "This notebook contains EDA of Precipitation data in order to gain information for the ETL process\n",
    "\n",
    "The main point of the analysis is to find out how to extract the precipitation for city of Chicago from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .appName('precipitation') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather station data\n",
    "Read the weather station data and have a peek at the schema and initial rows.\n",
    "\n",
    "The file was sapce delimited, with varying amount of whitespace between columns. We'll handle this by first reading the file to an RDD, parse the columns and convert it to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data_folder = '/Users/tomra/Projects/data-engineering/udacity-data-engineer-nanodegree/06-capstone-project/data'\n",
    "\n",
    "lines = spark.sparkContext.textFile(\n",
    "    os.path.join(data_folder, 'ghcnd', 'ghcnd-stations.txt')\n",
    ")\n",
    "split_lines = lines.map(lambda line: re.split('\\\\s+', line))\n",
    "final_lines = split_lines.map(lambda line: (line[0], line[1], line[2], line[3], ' '.join(line[4:-1])))\n",
    "df_stations = final_lines.toDF() \\\n",
    "    .selectExpr(\n",
    "        \"cast(_1 as string) as id\",\n",
    "        \"cast(_2 as float) as lat\",\n",
    "        \"cast(_3 as float) as lon\",\n",
    "        \"cast(_4 as float) as val\",\n",
    "        \"cast(_5 as string) as station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\n |-- id: string (nullable = true)\n |-- lat: float (nullable = true)\n |-- lon: float (nullable = true)\n |-- val: float (nullable = true)\n |-- station: string (nullable = true)\n\n+-----------+-------+--------+----+--------------------+\n|         id|    lat|     lon| val|             station|\n+-----------+-------+--------+----+--------------------+\n|ACW00011604|17.1167|-61.7833|10.1|ST JOHNS COOLIDGE...|\n|ACW00011647|17.1333|-61.7833|19.2|            ST JOHNS|\n|AE000041196| 25.333|  55.517|34.0|SHARJAH INTER. AI...|\n|AEM00041194| 25.255|  55.364|10.4|          DUBAI INTL|\n|AEM00041217| 24.433|  54.651|26.8|      ABU DHABI INTL|\n+-----------+-------+--------+----+--------------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "df_stations.printSchema()\n",
    "df_stations.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation data\n",
    "Next we'll read the actual precipitation data file and:\n",
    "* check amount of data\n",
    "* and have a peek at the top rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "df = spark.read \\\n",
    "    .format('csv') \\\n",
    "    .load(os.path.join(data_folder, 'ghcnd', '2016.csv')) \\\n",
    "    .selectExpr(\n",
    "        \"cast(_c0 as string) as id\",\n",
    "        \"cast(_c1 as string) as date\",\n",
    "        \"cast(_c2 as string) as element\",\n",
    "        \"cast(_c3 as float) as value\",\n",
    "        \"cast(_c4 as string) as m\",\n",
    "        \"cast(_c5 as string) as q\",\n",
    "        \"cast(_c6 as string) as s\",\n",
    "        \"cast(_c7 as string) as time\")\n",
    "df = df.withColumn('date', to_timestamp(df.date, 'yyyyMMdd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "35326976"
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            id       date element  value     m     q  s  time\n0  US1FLSL0019 2016-01-01    PRCP    3.0  None  None  N  None\n1  NOE00133566 2016-01-01    TMAX   95.0  None  None  E  None\n2  NOE00133566 2016-01-01    TMIN   23.0  None  None  E  None\n3  NOE00133566 2016-01-01    PRCP   10.0  None  None  E  None\n4  USC00141761 2016-01-01    TMAX   22.0  None  None  7  0700",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>element</th>\n      <th>value</th>\n      <th>m</th>\n      <th>q</th>\n      <th>s</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>US1FLSL0019</td>\n      <td>2016-01-01</td>\n      <td>PRCP</td>\n      <td>3.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>N</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NOE00133566</td>\n      <td>2016-01-01</td>\n      <td>TMAX</td>\n      <td>95.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>E</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NOE00133566</td>\n      <td>2016-01-01</td>\n      <td>TMIN</td>\n      <td>23.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>E</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NOE00133566</td>\n      <td>2016-01-01</td>\n      <td>PRCP</td>\n      <td>10.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>E</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>USC00141761</td>\n      <td>2016-01-01</td>\n      <td>TMAX</td>\n      <td>22.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>7</td>\n      <td>0700</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data\n",
    "The data file is to little use for us unless we can find a way to udnerstand where the weather station id's reside geographically.\n",
    "\n",
    "We'll make a left join of the station data on the precipication data to have human readable column for the location of each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df.join(df_stations, df.id == df_stations.id, 'left') \\\n",
    "    .select(df.id,\n",
    "            df.date,\n",
    "            df.element,\n",
    "            df.value,\n",
    "            df.time,\n",
    "            df_stations.station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can find some data from Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = merged_df.filter(merged_df.station.contains('CHICAGO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                           station  count\n0               IL CHICAGO 4.8 NNW      3\n1         IL CHICAGO MIDWAY AP 3SW    366\n2            IL WEST CHICAGO 2.7 N     85\n3        IL CHICAGO BOTANIC GARDEN    365\n4          IL CHICAGO PALWAUKEE AP    363\n5   IN (KB9UUO)NEW CHICAGO 0.6 SSE      2\n6        IL CHICAGO AURORA MUNI AP    360\n7               IL CHICAGO 5.5 ESE    360\n8               IL CHICAGO 6.4 NNE     34\n9      IL CHICAGO WAUKEGAN RGNL AP    363\n10        IL CHICAGO RIDGE 0.2 WSW    333\n11               IL CHICAGO 4.7 NE    311\n12            IL CHICAGO MIDWAY AP    366\n13              IL CHICAGO 2.7 WNW     95\n14       IL WEST CHICAGO DUPAGE AP    365\n15        IL CHICAGO OHARE INTL AP    366",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>IL CHICAGO 4.8 NNW</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>IL CHICAGO MIDWAY AP 3SW</td>\n      <td>366</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IL WEST CHICAGO 2.7 N</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>IL CHICAGO BOTANIC GARDEN</td>\n      <td>365</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IL CHICAGO PALWAUKEE AP</td>\n      <td>363</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>IN (KB9UUO)NEW CHICAGO 0.6 SSE</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>IL CHICAGO AURORA MUNI AP</td>\n      <td>360</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>IL CHICAGO 5.5 ESE</td>\n      <td>360</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>IL CHICAGO 6.4 NNE</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>IL CHICAGO WAUKEGAN RGNL AP</td>\n      <td>363</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>IL CHICAGO RIDGE 0.2 WSW</td>\n      <td>333</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>IL CHICAGO 4.7 NE</td>\n      <td>311</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>IL CHICAGO MIDWAY AP</td>\n      <td>366</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>IL CHICAGO 2.7 WNW</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>IL WEST CHICAGO DUPAGE AP</td>\n      <td>365</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>IL CHICAGO OHARE INTL AP</td>\n      <td>366</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 183
    }
   ],
   "source": [
    "filtered_df.filter(filtered_df.element == \"PRCP\").groupBy('station').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chicago Midway Airport contains precipitation for every day (2016 was a leap year) so we'll settle on one of them.\n",
    "\n",
    "As a result we'll check the station ID so we can filter the data in ETL process more efficiently. Since we're only interested in the weather for one location there will be little benefit in repeating this join process in the ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+-------+--------+-----+--------------------+\n|         id|    lat|     lon|  val|             station|\n+-----------+-------+--------+-----+--------------------+\n|USC00111577|41.7372|-87.7775|189.0|IL CHICAGO MIDWAY...|\n+-----------+-------+--------+-----+--------------------+\n\n"
    }
   ],
   "source": [
    "df_stations.filter(df_stations.station == 'IL CHICAGO MIDWAY AP 3SW').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final filtering and creation of DataFrame for checking basic statistical information about the precipitation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_df = merged_df \\\n",
    "    .filter(merged_df.element == 'PRCP') \\\n",
    "    .filter(merged_df.id == 'USC00111577')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "366"
     },
     "metadata": {},
     "execution_count": 185
    }
   ],
   "source": [
    "precip_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  summary           id element              value    time  \\\n0   count          366     366                366     366   \n1    mean         None    None   29.1448087431694  2400.0   \n2  stddev         None    None  73.57138598660973     0.0   \n3     min  USC00111577    PRCP                0.0    2400   \n4     max  USC00111577    PRCP              508.0    2400   \n\n                    station  \n0                       366  \n1                      None  \n2                      None  \n3  IL CHICAGO MIDWAY AP 3SW  \n4  IL CHICAGO MIDWAY AP 3SW  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>id</th>\n      <th>element</th>\n      <th>value</th>\n      <th>time</th>\n      <th>station</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>count</td>\n      <td>366</td>\n      <td>366</td>\n      <td>366</td>\n      <td>366</td>\n      <td>366</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mean</td>\n      <td>None</td>\n      <td>None</td>\n      <td>29.1448087431694</td>\n      <td>2400.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>stddev</td>\n      <td>None</td>\n      <td>None</td>\n      <td>73.57138598660973</td>\n      <td>0.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>min</td>\n      <td>USC00111577</td>\n      <td>PRCP</td>\n      <td>0.0</td>\n      <td>2400</td>\n      <td>IL CHICAGO MIDWAY AP 3SW</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max</td>\n      <td>USC00111577</td>\n      <td>PRCP</td>\n      <td>508.0</td>\n      <td>2400</td>\n      <td>IL CHICAGO MIDWAY AP 3SW</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 187
    }
   ],
   "source": [
    "precip_df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We've successfully joined the station data with measurement records, identified weather stations in Chicago, chosen one, and as a result extracted daily precipitation values that can be used in the weather facts table.\n",
    "\n",
    "We'll filter the raw data in ETL process like done above:\n",
    "* Only include station id `USC00111577` that corresponds to Chicago Midway Station weather station\n",
    "* Only incldue element value `PRCP` that corresponds to precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}